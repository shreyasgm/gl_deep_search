[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "gl-deep-search"
version = "0.1.0"
description = "An agentic RAG system that helps users query Growth Lab-specific unstructured data"
readme = "README.md"
requires-python = ">=3.12,<3.13"
license = { text = "CC-BY-NC-SA 4.0" }
authors = [
    { name = "Shreyas Gadgin Matha" },
    { name = "Karan Daryanani" },
    { name = "Santiago Segovia Baquero" },
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Science/Research",
    "License :: Other/Proprietary License",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    # Core dependencies shared across all components
    "pydantic>=2",
    "python-dotenv>=1",
    "loguru",
    "tqdm",
    "pre-commit>=4.1.0",
    "ruff>=0.11.0",
    "mypy>=1.15.0",
    "black>=25.1.0",
    "sqlmodel>=0.0.8",
    "pytest>=7.4.0",
    "aiohttp>=3.8.0,!=3.11.14", # Avoid yanked version 3.11.14
    "aiofiles",
]

[project.urls]
Homepage = "https://github.com/shreyasgm/gl-deep-search"
Repository = "https://github.com/shreyasgm/gl-deep-search"
"Bug Tracker" = "https://github.com/shreyasgm/gl-deep-search/issues"

[project.optional-dependencies]
# ETL pipeline dependencies
etl = [
    # Web scraping
    "beautifulsoup4",
    "requests",
    "lxml",
    "scrapy",
    "backoff",
    "asyncio",
    "aiohttp>=3.8.0,!=3.11.14", # Avoid yanked version 3.11.14
    "aiofiles",
    "scidownl>=1.0.2",
    "curl_cffi>=0.7.0",  # Browser TLS fingerprint impersonation for Cloudflare bypass
    # PDF processing and OCR
    "langdetect",
    "unstructured[all-docs]",
    "docling",
    "marker-pdf>=1.0.0",
    # Vector databases and embeddings
    "qdrant-client",
    "sentence-transformers",
    "openai",
    "cohere",
    # Data
    "pandas",
    "numpy",
    "seaborn",
    # Cloud storage
    "google-cloud-storage",
    "tiktoken>=0.9.0",
    "pdfminer.six>=20211012",
    "pyarrow",
]

# Backend service dependencies
service = [
    # API framework
    "fastapi",
    "uvicorn",
    "pydantic-settings",

    # Vector search
    "qdrant-client",

    # LLM frameworks
    "langgraph",
    "langchain",
    "langchain-community",
    "langchain-openai",
    "langchain-anthropic",

    # LLM providers
    "openai",
    "anthropic",

    # Observability
    "langsmith",

    # Embeddings
    "sentence-transformers",
    "fastembed",
    "cohere",
]

# Frontend dependencies
frontend = [
    "streamlit",
    # "chainlit",
    "requests",
    # "plotly",
    "pandas",
    # "altair",
    # "streamlit-extras",
]

# Development tools
dev = [
    # Testing
    "pytest",
    "pytest-cov",
    "pytest-mock",
    "pytest-asyncio",

    # MCP for Cursor or other IDE
    "browser-use",
    "playwright",

    # Linting, formatting, type checking
    "ruff==0.11.0",
    "mypy==1.15.0",
    "types-requests",
    "types-PyYAML",
    "types-tqdm",
    "types-aiofiles",
    "pandas-stubs",
    "types-beautifulsoup4",

    # Benchmark / profiling
    "psutil",

    # Pre-commit hooks
    "pre-commit",

    # Documentation
    "mkdocs",
    "mkdocs-material",

    "sqlmodel>=0.0.8",
    "aiohttp>=3.8.0,!=3.11.14", # Avoid yanked version 3.11.14
    "aiofiles",
]

# Dependencies for running in production
prod = [
    "gunicorn",
    "google-cloud-logging",
    "google-cloud-secret-manager",
    "google-cloud-monitoring",
]

# All dependencies (for CI or full development environment)
all = [
    "gl-deep-search[etl,service,frontend,dev,prod]",
]

[tool.ruff]
# Basic linting configuration
line-length = 88
target-version = "py312"
lint.select = [
    "E",    # Critical errors
    "F",    # Pyflakes
    "B",    # Bug detection
    "I",    # Import sorting
    "N",    # Naming
    "T20",  # Print statements
    "UP",   # Python upgrades
    "D",    # Documentation (will be set to warning)
    "ANN",  # Type annotations (will be set to warning)
]
lint.unfixable = ["D", "ANN"]

# Make documentation and type annotation rules generate warnings instead of errors
[tool.ruff.lint.per-file-ignores]
"**/*" = ["D", "ANN", "E722", "F841"]  # Ignore documentation, type annotations, bare except, and unused vars
"**/test_*.py" = ["T201"]  # Ignore print statements in test files
"**/tests/**/*.py" = ["T201"]  # Ignore print statements in test files

# Configure specific documentation rules
[tool.ruff.lint.pydocstyle]
convention = "google"  # Use Google-style docstrings

# Configure Ruff to handle formatting
[tool.ruff.format]
quote-style = "double"
indent-style = "space"
line-ending = "auto"
skip-magic-trailing-comma = false

# Configure import sorting
[tool.ruff.lint.isort]
known-first-party = ["gl_deep_search"]
force-single-line = false
section-order = ["future", "standard-library", "third-party", "first-party", "local-folder"]

[tool.mypy]
python_version = "3.12"
ignore_missing_imports = true
show_error_codes = true

# Convert only specific errors to warnings, particularly union-attr and similar ones from BeautifulSoup
# See https://mypy.readthedocs.io/en/stable/error_codes.html
disable_error_code = ["union-attr", "arg-type", "index", "misc", "call-overload", "return-value"]

# Exclude openalex file downloader files from mypy checking
exclude = [
    "backend/etl/utils/oa_file_downloader.py",
    "backend/etl/scripts/run_openalex_file_downloader.py",
    "backend/tests/etl/test_oa_file_downloader.py"
]

[tool.pytest.ini_options]
# Register custom marks
markers = [
    "integration: mark tests as integration tests that may require real data",
    "asyncio: mark a test as an asyncio coroutine",
]
# Configure pytest-asyncio plugin
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
asyncio_default_test_loop_scope = "function"

[tool.hatch.build.targets.wheel]
packages = ["backend"]
