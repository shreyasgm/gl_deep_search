# Growth Lab Deep Search - ETL Configuration

# Environment settings (will be overridden by .env variables)
environment: "development"  # Options: development, production

# Data sources
sources:
  growth_lab:
    base_url: "https://growthlab.hks.harvard.edu/publications-home/repository"
    scrape_delay: 2.0  # seconds between requests
    concurrency_limit: 2  # Maximum number of concurrent requests
    max_retries: 5  # Maximum number of retries for failed requests
    retry_base_delay: 5.0  # Initial delay in seconds before retrying
    retry_max_delay: 30.0  # Maximum delay in seconds before retrying
    max_concurrent_downloads: 10
    download_timeout: 60
    redownload_existing: false
    remove_outdated_files: true

  openalex:
    author_id: "A5034550995" # Ricardo Hausmann's author ID
    email: "parlay.donegal.0j@icloud.com" # for polite OpenAlex API use
    unpaywall_email: "parlay.donegal.0j@icloud.com" # for Unpaywall API access
    max_retries_per_page: 3
    max_overall_retries: 10
    redownload_existing: false
    remove_outdated_files: true

# Growth Lab file downloader configuration
gl_file_downloader:
  download_delay: 1.0
  max_retries: 5
  retry_base_delay: 1.0
  retry_max_delay: 60.0
  min_file_size: 1024  # 1KB
  max_file_size: 100_000_000  # 100MB
  user_agent_list:
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/120.0.0.0"

# File processing
file_processing:
  ocr:
    default_model: "marker"  # Options: marker, docling
    max_concurrent: 4
    min_chars_per_page: 100
    max_pages: 250            # Skip PDFs longer than this (0 = no limit)

    marker:
      force_ocr: true
      # Marker auto-detects optimal batch sizes based on device (CPU/CUDA)
      # and available memory. Override only if needed for constrained environments:
      #   pdftext_workers: 1         # default 4; set to 1 to avoid OOM on <8GB machines
      #   layout_batch_size: 2       # default auto (6 CPU, 12 CUDA)
      #   detection_batch_size: 2    # default auto (4 CPU, 10 CUDA)
      #   recognition_batch_size: 4  # default auto (32 CPU, 48 CUDA)
      #   extract_images: false

    docling:
      do_ocr: true
      do_table_structure: true
      table_mode_accurate: true
      do_picture_description: false
      num_threads: 4

  embedding:
    model: "sentence_transformer"  # Options: openrouter, sentence_transformer
    model_name: "Qwen/Qwen3-Embedding-8B"
    dimensions: 1024               # MRL truncation from native 4096; changing requires full re-embedding
    max_tokens: 32768              # Qwen3-Embedding-8B context window
    batch_size: 32
    max_retries: 3                 # Maximum retry attempts for failed API calls
    retry_delays: [1, 2, 4]        # Exponential backoff delays in seconds
    timeout: 30                    # API request timeout in seconds
    rate_limit_delay: 0.1          # Delay between batches to respect rate limits

  chunking:
    enabled: true
    strategy: "hybrid"             # Options: fixed, sentence, structure, hybrid
    # NOTE: All size limits below are in TOKENS (not characters) to ensure
    # compatibility with embedding model token limits (Qwen3-Embedding-8B: 32768)
    chunk_size: 500                # target tokens per chunk
    chunk_overlap: 50              # tokens of overlap between chunks
    min_chunk_size: 50             # minimum viable chunk size in tokens
    max_chunk_size: 8000           # maximum tokens (embedding model limit is 8192)
    preserve_structure: true       # respect document hierarchy (headers, sections)
    respect_sentences: true        # prefer sentence boundaries for splits
    structure_markers:             # patterns for detecting document structure
      - "^#{1,6}\\s+"              # markdown headers
      - "^\\d+\\.\\s+"             # numbered lists
      - "^[A-Z][A-Z\\s]+:"         # section labels like "INTRODUCTION:"

# Storage
storage:
  vector_db:
    name: "qdrant"
    collections:
      documents: "gl_documents"
      chunks: "gl_chunks"


# Runtime detection
runtime:
  detect_automatically: true
  slurm_indicators: ["SLURM_JOB_ID", "SLURM_STEP_ID"]
  local_storage_path: "data/"
  gcs_bucket: "gl-deep-search"
  sync_to_gcs: true # Only used in SLURM environment
