# Growth Lab Deep Search - ETL Configuration

# Environment settings (will be overridden by .env variables)
environment: "development"  # Options: development, production

# Data sources
sources:
  growth_lab:
    base_url: "https://growthlab.hks.harvard.edu/publications"
    scrape_delay: 2.0  # seconds between requests
    concurrency_limit: 2  # Maximum number of concurrent requests
    max_retries: 5  # Maximum number of retries for failed requests
    retry_base_delay: 5.0  # Initial delay in seconds before retrying
    retry_max_delay: 30.0  # Maximum delay in seconds before retrying
    max_concurrent_downloads: 10
    download_timeout: 60
    redownload_existing: false
    remove_outdated_files: true

  openalex:
    author_id: "A5034550995" # Ricardo Hausmann's author ID
    email: "parlay.donegal.0j@icloud.com" # for polite OpenAlex API use
    unpaywall_email: "parlay.donegal.0j@icloud.com" # for Unpaywall API access
    max_retries_per_page: 3
    max_overall_retries: 10
    redownload_existing: false
    remove_outdated_files: true

# Growth Lab file downloader configuration
gl_file_downloader:
  download_delay: 1.0
  max_retries: 5
  retry_base_delay: 1.0
  retry_max_delay: 60.0
  min_file_size: 1024  # 1KB
  max_file_size: 100_000_000  # 100MB
  user_agent_list:
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15"
    - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/120.0.0.0"

# File processing
file_processing:
  ocr:
    default_model: "docling"  # Options: docling, marker, gemini_flash
    max_concurrent: 4
    chunk_size: 1000
    chunk_overlap: 200
    language_detection_pages: 5

  embedding:
    model: "openai"  # Options: openai, sentence_transformer
    dimensions: 1536
    batch_size: 32

# Storage
storage:
  vector_db:
    name: "qdrant"
    collections:
      documents: "gl_documents"
      chunks: "gl_chunks"


# Runtime detection
runtime:
  detect_automatically: true
  slurm_indicators: ["SLURM_JOB_ID", "SLURM_STEP_ID"]
  local_storage_path: "data/"
  gcs_bucket: "gl-deep-search"
  sync_to_gcs: true # Only used in SLURM environment
