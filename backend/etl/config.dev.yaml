# Growth Lab Deep Search - Development Mode Overrides
#
# This file contains ONLY the settings that differ from the base config
# for lightweight local development. It is deep-merged on top of config.yaml
# when the orchestrator is run with --dev.
#
# Purpose: avoid loading heavy ML models (Marker ~4GB, Qwen3-8B ~16GB)
# so the pipeline can iterate quickly on CPU/MPS.
#
# Usage:
#   uv run python -m backend.etl.orchestrator --dev --skip-scraping --download-limit 3

file_processing:
  ocr:
    default_model: "unstructured"
    max_pdfs: 10

    unstructured:
      strategy: "fast"          # pdfminer text extraction only, no ML models
      languages: ["eng"]
      extract_images: false

  embedding:
    model_name: "all-MiniLM-L6-v2"  # 80MB, instant CPU load
    dimensions: 384                  # Native output dimensions (no MRL truncation)
    max_tokens: 256                  # True effective limit (model truncates at 256)
    batch_size: 64                   # Small model can batch more

  chunking:
    chunk_size: 100                  # ~100 tokens â€” safe for 256 token limit
    chunk_overlap: 20
    max_chunk_size: 200              # Hard cap: clamped to min(200, 256-100) = 156

  tagging:
    max_docs: 10                     # Limit tagging to 10 documents in dev mode
